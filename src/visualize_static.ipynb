{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Visualize how well the class embeddings attend on words and\n",
    "sentences. The expected result would be that the “married”\n",
    "class embedding, for example, attends heavily on words and\n",
    "sentences related to marriage like “married”, “husband”, “wife”, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dao.ryn.text.text_dir import TextDir\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from random import shuffle\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.core.display import display, HTML\n",
    "from jinja2 import Template\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch import tensor, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dao.ower.ower_dir import Sample, OwerDir\n",
    "from data.power.texter_pkl import TexterPkl\n",
    "from util import plot_tensor\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "texter_pkl_path = '../data/power/texter-v2/static_attend_cde-irt-5-clean.pkl'\n",
    "\n",
    "# Input data\n",
    "ower_dir_path = '../data/ower-v4/cde-irt-100-5/'\n",
    "class_count = 100\n",
    "sent_count = 5\n",
    "\n",
    "text_dir_path = '../data/ryn/text/cde-irt-5-clean/'\n",
    "\n",
    "# Pre-processing\n",
    "sent_len = 64\n",
    "\n",
    "# Testing\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Check that (input) OWER Texter PKL exists\n",
    "#\n",
    "\n",
    "texter_pkl = TexterPkl(Path(texter_pkl_path))\n",
    "texter_pkl.check()\n",
    "\n",
    "#\n",
    "# Check that (input) OWER Directory exists\n",
    "#\n",
    "\n",
    "ower_dir = OwerDir(Path(ower_dir_path))\n",
    "ower_dir.check()\n",
    "\n",
    "#\n",
    "# Check that (input) Ryn Text Directory exists\n",
    "#\n",
    "\n",
    "text_dir = TextDir(Path(text_dir_path))\n",
    "text_dir.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Texter and test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\Tobias\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchtext\\data\\example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "C:\\Users\\Tobias\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "texter = texter_pkl.load().cpu()\n",
    "\n",
    "train_set, valid_set, test_set, vocab = ower_dir.read_datasets(class_count, sent_count)\n",
    "\n",
    "\n",
    "def generate_batch(batch: List[Sample]) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "\n",
    "    ent_batch, gt_classes_batch, tok_lists_batch = zip(*batch)\n",
    "\n",
    "    cropped_tok_lists_batch = [[tok_list[:sent_len]\n",
    "                                for tok_list in tok_lists] for tok_lists in tok_lists_batch]\n",
    "\n",
    "    padded_tok_lists_batch = [[tok_list + [0] * (sent_len - len(tok_list))\n",
    "                               for tok_list in tok_lists] for tok_lists in cropped_tok_lists_batch]\n",
    "\n",
    "    for padded_tok_lists in padded_tok_lists_batch:\n",
    "        shuffle(padded_tok_lists)\n",
    "\n",
    "    return tensor(ent_batch), tensor(padded_tok_lists_batch), tensor(gt_classes_batch)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, collate_fn=generate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Debug Info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Line must contain single spaces only as separator. Replacing each whitespace with single space. Line: 'Q777403:Washington University in St.\\xa0Louis 14299\\n'\n"
     ]
    }
   ],
   "source": [
    "# Load class info\n",
    "rel_tail_freq_lbl_list = ower_dir.classes_tsv.load()\n",
    "ent_to_lbl = ower_dir.ent_labels_txt.load()\n",
    "\n",
    "# load test ent labels\n",
    "test_ent_to_sents = text_dir.ow_test_sents_txt.load()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict test entities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-31-784108fcc213>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mlogits_batch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0matts_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtexter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msents_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m     \u001B[0mno_att_logits_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtexter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward_without_attention\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msents_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\HSRM\\Master\\Thesis\\dev\\24-visualize-attentions\\src\\models\\ower.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, tok_lists_batch)\u001B[0m\n\u001B[0;32m     57\u001B[0m         \u001B[1;31m# > sents_batch      (batch_size, sent_count, emb_size)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m         \u001B[0msents_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membed_tok_lists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtok_lists_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m         \u001B[1;31m# Calculate attentions (which class matches which sentences)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\HSRM\\Master\\Thesis\\dev\\24-visualize-attentions\\src\\models\\ower.py\u001B[0m in \u001B[0;36membed_tok_lists\u001B[1;34m(self, tok_lists_batch)\u001B[0m\n\u001B[0;32m    110\u001B[0m         \u001B[1;31m# > sents_batch  (batch_size, sent_count, emb_size)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memb_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mflat_sents\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[0msents_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mflat_sents\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msent_count\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memb_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\HSRM\\Master\\Thesis\\dev\\24-visualize-attentions\\src\\models\\ower.py\u001B[0m in \u001B[0;36membed_tok_lists\u001B[1;34m(self, tok_lists_batch)\u001B[0m\n\u001B[0;32m    110\u001B[0m         \u001B[1;31m# > sents_batch  (batch_size, sent_count, emb_size)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memb_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mflat_sents\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[0msents_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mflat_sents\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msent_count\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memb_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2020.2.2\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2020.2.2\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1162\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "limit_classes = 4\n",
    "\n",
    "texter.eval()\n",
    "\n",
    "for i, (ent_batch, sents_batch, gt_batch) in enumerate(test_loader):\n",
    "    if i == 1:\n",
    "        break\n",
    "\n",
    "    logits_batch, atts_batch = texter(sents_batch)\n",
    "    no_att_logits_batch = texter.forward_without_attention(sents_batch)\n",
    "\n",
    "    for ent, sents, gt, logits, atts, no_att_logits in \\\n",
    "            zip(ent_batch, sents_batch, gt_batch, logits_batch, atts_batch, no_att_logits_batch):\n",
    "        print(ent_to_lbl[ent.item()])\n",
    "\n",
    "        print('sents')\n",
    "        pprint(list(test_ent_to_sents[ent.item()]))\n",
    "\n",
    "        print('gt')\n",
    "        pprint(gt[:limit_classes])\n",
    "\n",
    "        print('logits')\n",
    "        pprint(logits[:limit_classes])\n",
    "\n",
    "        print('atts')\n",
    "        pprint(atts[:limit_classes])\n",
    "\n",
    "        class_labels = [rel_tail_freq_lbl_list[c][3] for c in range(class_count)][:limit_classes]\n",
    "        # class_labels = [f'class {c}' for c in range(class_count)][:limit_classes]\n",
    "        sent_labels = [f'sent {s}' for s in range(sent_count)]\n",
    "        plot_tensor(atts[:limit_classes], 'atts', [class_labels, sent_labels])\n",
    "\n",
    "        print('no_att_logits')\n",
    "        pprint(no_att_logits[:,:limit_classes])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_first_batch = False\n",
    "\n",
    "for epoch in range(epoch_count):\n",
    "\n",
    "    ## Train\n",
    "\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # Valid gt/pred classes across all batches\n",
    "    train_gt_classes_stack: List[List[int]] = []\n",
    "    train_pred_classes_stack: List[List[int]] = []\n",
    "\n",
    "    for batch_idx, (_, sents_batch, gt_classes_batch) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch}')):\n",
    "        sents_batch = sents_batch.to(device)\n",
    "        gt_classes_batch = gt_classes_batch.to(device)\n",
    "\n",
    "        logits_batch = classifier(sents_batch)\n",
    "\n",
    "        loss = criterion(logits_batch, gt_classes_batch.float())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred_classes_batch = (logits_batch > 0).int()\n",
    "\n",
    "        train_gt_classes_stack += gt_classes_batch.cpu().numpy().tolist()\n",
    "        train_pred_classes_stack += pred_classes_batch.cpu().numpy().tolist()\n",
    "\n",
    "        #\n",
    "        # Log first batch\n",
    "        #\n",
    "\n",
    "        if log_first_batch and batch_idx == 0:\n",
    "\n",
    "            dlb = logits_batch.cpu().detach().numpy()  # logits batch\n",
    "            dpb = pred_classes_batch.cpu().detach().numpy()  # predicted classes batch\n",
    "            dgb = gt_classes_batch.cpu().detach().numpy()  # ground truth classes batch\n",
    "            dsb = sents_batch.cpu().detach().numpy()  # sentences batch\n",
    "\n",
    "            df_cols = ['entity', 'logits', 'p', 'gt', 'sents']\n",
    "            df_data = [('foo', logits, pred_classes, classes, [[vocab.itos[tok] for tok in sent] for sent in sents])\n",
    "                       for logits, pred_classes, classes, sents in zip(dlb, dpb, dgb, dsb)]\n",
    "\n",
    "            df = pd.DataFrame(df_data[:8], columns=df_cols)\n",
    "            display(df)\n",
    "\n",
    "            display_atts = debug['atts_batch'][:8].cpu()\n",
    "            ent_labels = [f'ent {i}' for i in range(batch_size)]\n",
    "            class_labels = [f'clss {i}' for i in range(class_count)]\n",
    "            sent_labels = [f'sent {i}' for i in range(sent_count)]\n",
    "            plot_tensor(display_atts, 'atts_batch', [ent_labels, class_labels, sent_labels])\n",
    "\n",
    "    ## Validate\n",
    "\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    # Valid gt/pred classes across all batches\n",
    "    valid_gt_classes_stack: List[List[int]] = []\n",
    "    valid_pred_classes_stack: List[List[int]] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (ent_batch, sents_batch, gt_classes_batch) in enumerate(tqdm(valid_loader, desc=f'Epoch {epoch}')):\n",
    "            sents_batch = sents_batch.to(device)\n",
    "            gt_classes_batch = gt_classes_batch.to(device)\n",
    "\n",
    "            logits_batch = classifier(sents_batch)\n",
    "\n",
    "            loss = criterion(logits_batch, gt_classes_batch.float())\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            pred_classes_batch = (logits_batch > 0).int()\n",
    "\n",
    "            valid_gt_classes_stack += gt_classes_batch.cpu().numpy().tolist()\n",
    "            valid_pred_classes_stack += pred_classes_batch.cpu().numpy().tolist()\n",
    "\n",
    "            #\n",
    "            # Print first batch\n",
    "            #\n",
    "\n",
    "            if log_first_batch and batch_idx == 0:\n",
    "\n",
    "                dlb = logits_batch.cpu().detach().numpy()  # logits batch\n",
    "                dpb = pred_classes_batch.cpu().detach().numpy()  # predicted classes batch\n",
    "                dgb = gt_classes_batch.cpu().detach().numpy()  # ground truth classes batch\n",
    "                dsb = sents_batch.cpu().detach().numpy()  # sentences batch\n",
    "\n",
    "                df_cols = ['entity', 'logits', 'p', 'gt', 'sents']\n",
    "                df_data = [('foo', logits, pred_classes, classes, [[vocab.itos[tok] for tok in sent] for sent in sents])\n",
    "                           for logits, pred_classes, classes, sents in zip(dlb, dpb, dgb, dsb)]\n",
    "\n",
    "                df = pd.DataFrame(df_data[:8], columns=df_cols)\n",
    "                display(df)\n",
    "\n",
    "                display_atts = debug['atts_batch'][:8].cpu()\n",
    "                ent_labels = [f'ent {i}' for i in range(batch_size)]\n",
    "                class_labels = [f'clss {i}' for i in range(class_count)]\n",
    "                sent_labels = [f'sent {i}' for i in range(sent_count)]\n",
    "                plot_tensor(display_atts, 'atts_batch', [ent_labels, class_labels, sent_labels])\n",
    "\n",
    "\n",
    "    ## Log loss\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    valid_loss /= len(valid_loader)\n",
    "\n",
    "    writer.add_scalars('loss', {'train': train_loss, 'valid': valid_loss}, epoch)\n",
    "\n",
    "    ## Log metrics for most/least common classes\n",
    "\n",
    "    # tps = train precisions, vps = valid precisions, etc.\n",
    "    tps = precision_score(train_gt_classes_stack, train_pred_classes_stack, average=None)\n",
    "    vps = precision_score(valid_gt_classes_stack, valid_pred_classes_stack, average=None)\n",
    "    trs = recall_score(train_gt_classes_stack, train_pred_classes_stack, average=None)\n",
    "    vrs = recall_score(valid_gt_classes_stack, valid_pred_classes_stack, average=None)\n",
    "    tfs = f1_score(train_gt_classes_stack, train_pred_classes_stack, average=None)\n",
    "    vfs = f1_score(valid_gt_classes_stack, valid_pred_classes_stack, average=None)\n",
    "\n",
    "    # Log metrics for each class c\n",
    "    for c, (tp, vp, tr, vr, tf, vf), in enumerate(zip(tps, vps, trs, vrs, tfs, vfs)):\n",
    "\n",
    "        # many classes -> log only first and last ones\n",
    "        if (class_count > 2 * 3) and (3 <= c <= len(tps) - 3 - 1):\n",
    "            continue\n",
    "\n",
    "        writer.add_scalars('precision', {f'train_{c}': tp}, epoch)\n",
    "        writer.add_scalars('precision', {f'valid_{c}': vp}, epoch)\n",
    "        writer.add_scalars('recall', {f'train_{c}': tr}, epoch)\n",
    "        writer.add_scalars('recall', {f'valid_{c}': vr}, epoch)\n",
    "        writer.add_scalars('f1', {f'train_{c}': tf}, epoch)\n",
    "        writer.add_scalars('f1', {f'valid_{c}': vf}, epoch)\n",
    "\n",
    "    ## Log macro metrics over all classes\n",
    "\n",
    "    # mtp = mean train precision, mvp = mean valid precision, etc.\n",
    "    mtp = tps.mean()\n",
    "    mvp = vps.mean()\n",
    "    mtr = trs.mean()\n",
    "    mvr = vrs.mean()\n",
    "    mtf = tfs.mean()\n",
    "    mvf = vfs.mean()\n",
    "\n",
    "    writer.add_scalars('precision', {'train': mtp}, epoch)\n",
    "    writer.add_scalars('precision', {'valid': mvp}, epoch)\n",
    "    writer.add_scalars('recall', {'train': mtr}, epoch)\n",
    "    writer.add_scalars('recall', {'valid': mvr}, epoch)\n",
    "    writer.add_scalars('f1', {'train': mtf}, epoch)\n",
    "    writer.add_scalars('f1', {'valid': mvf}, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc top class-word attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_embs = classifier.class_embs\n",
    "tok_embs = classifier.embedding_bag.weight\n",
    "\n",
    "tok_atts = torch.einsum('ce, ve -> cv', class_embs, tok_embs)\n",
    "result = tok_atts.sort(descending=True)\n",
    "indices = result.indices.cpu().numpy()\n",
    "values = result.values.cpu().detach().numpy()\n",
    "\n",
    "rel_tail_freq_lbl_tuples = ower_dir.classes_tsv.load()\n",
    "_, _, _, class_labels = zip(*rel_tail_freq_lbl_tuples)\n",
    "\n",
    "for c, c_lbl in zip(range(class_count), class_labels):\n",
    "    print('\\n', c_lbl)\n",
    "    for tok, val in zip(indices[c][:10], values[c][:10]):\n",
    "        print('\\t{} ({:.2f})'.format(vocab.itos[tok], val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize class-word attentions in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tok_atts /= max(-tok_atts.min(), tok_atts.max())\n",
    "tok_atts *= 512\n",
    "tok_atts += 128\n",
    "\n",
    "def get_color(att: float) -> str:\n",
    "    att = max(min(att, 255), 0)\n",
    "    r, g, b = pyplot.get_cmap('viridis').colors[int(att)]\n",
    "\n",
    "    return f'rgba({int(r * 256)}, {int(g * 256)}, {int(b * 256)}, 0.5)'\n",
    "\n",
    "\n",
    "def render_sent(class_: int, sent: List[int]) -> str:\n",
    "\n",
    "    words = ['<span style=\"background-color: {}\">{}</span>'.format(\n",
    "                get_color(tok_atts[class_][tok]),\n",
    "                vocab.itos[tok] if tok != 0 else '_'\n",
    "            ) for tok in sent]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def render_table(sents: List[List[int]]) -> None:\n",
    "    short_class_labels = [class_label[-20:] for class_label in class_labels]\n",
    "\n",
    "    display(HTML(Template('''\n",
    "        <style>\n",
    "            table.atts td { text-align: left }\n",
    "        </style>\n",
    "\n",
    "        <table class='atts'>\n",
    "            <tr>\n",
    "                <th></th>\n",
    "\n",
    "                {% for i in range(len(sents)) %}\n",
    "                <th> Sent {{ i }} </th>\n",
    "                {% endfor %}\n",
    "            </tr>\n",
    "\n",
    "            {% for c in range(len(class_labels)) %}\n",
    "            <tr>\n",
    "                <th>{{ class_labels[c] }}</th>\n",
    "\n",
    "                {% for sent in sents %}\n",
    "                <td>{{ render_sent(c, sent) }}</td>\n",
    "                {% endfor %}\n",
    "            </tr>\n",
    "            {% endfor %}\n",
    "        </table>\n",
    "    ''').render(\n",
    "        sents=sents,\n",
    "        class_labels=short_class_labels,\n",
    "        render_sent=render_sent,\n",
    "        len=len\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ent_to_lbl = ower_dir.ent_labels_txt.load()\n",
    "\n",
    "logits_batch = logits_batch.cpu()\n",
    "pred_classes_batch = pred_classes_batch.cpu()\n",
    "gt_classes_batch = gt_classes_batch.cpu()\n",
    "atts_batch = debug['atts_batch'].cpu()\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    ent = ent_batch[i].item()\n",
    "\n",
    "    display(HTML('<h1>{} ({})</h1>'.format(ent_to_lbl[ent], ent)))\n",
    "\n",
    "    texts = [' '.join([vocab.itos[tok] if tok != 0 else '_' for tok in tok_list])\n",
    "             for tok_list in sents_batch[i]]\n",
    "\n",
    "    display(HTML(Template('''\n",
    "        <ul>\n",
    "            {% for text in texts %}\n",
    "                <li> {{ text }} </li>\n",
    "            {% endfor %}\n",
    "        </ul>\n",
    "    ''').render(texts=texts)))\n",
    "\n",
    "    print(class_labels)\n",
    "    print('logits =', logits_batch[i])\n",
    "    print('pred =', pred_classes_batch[i])\n",
    "    print('gt =', gt_classes_batch[i])\n",
    "\n",
    "    sent_labels = [f'sent {i}' for i in range(sent_count)]\n",
    "    plot_tensor(atts_batch[i], 'atts', [class_labels, sent_labels])\n",
    "\n",
    "    display(HTML(render_table(sents_batch[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}